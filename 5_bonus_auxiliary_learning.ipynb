{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some extra package installations for your conda environment\n",
    "\n",
    "!pip install cython\n",
    "!pip install git+git://github.com/funkelab/lsd.git\n",
    "!pip install git+git://github.com/funkey/gunpowder.git\n",
    "!pip install git+git://github.com/funkey/waterz.git\n",
    "!pip install git+git://github.com/funkelab/funlib.segment.git\n",
    "!pip install git+git://github.com/funkelab/daisy.git\n",
    "!pip install git+git://github.com/funkelab/funlib.learn.torch.git\n",
    "!pip uninstall -y tornado\n",
    "!pip install tornado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7df222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import Image\n",
    "\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import zarr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompress data\n",
    "from shutil import unpack_archive\n",
    "unpack_archive(os.path.join('datasets','data_epithelia.tar.gz'), './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfec17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='utils/epithelia.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d998d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "inspect the structure of data\n",
    "\n",
    " └── volumes\n",
    "     ├── gt_affs (2, 256, 256) uint8--> affinities map, 2 channels\n",
    "     ├── gt_fgbg (1, 256, 256) uint8--> foreground and background semantic segmentation\n",
    "     ├── gt_labels (1, 256, 256) uint16--> instance segmentation, each instance has a different integer label\n",
    "     ├── gt_tanh (1, 256, 256) float32-->squared distance transformation \n",
    "     └── raw (1, 256, 256) float32--> raw input for the model\n",
    "'''\n",
    "\n",
    "sample_path = glob.glob(os.path.join(\"data_epithelia\", \"train\", \"*.zarr\"))\n",
    "first_data = zarr.open(sample_path[0], 'r')\n",
    "print(first_data.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use local shape descriptors as an auxiliary learning task for training affinities\n",
    "# see here for info: https://localshapedescriptors.github.io/\n",
    "\n",
    "from lsd import local_shape_descriptor\n",
    "\n",
    "files = glob.glob(os.path.join(\"data_epithelia\", \"train\", \"*.zarr\"))\n",
    "\n",
    "f = zarr.open(files[random.randint(0,len(files)-1)])\n",
    "\n",
    "raw = f['volumes/raw'][:,0:150,0:150]\n",
    "labels = f['volumes/gt_labels'][:,0:150,0:150].astype(np.uint64)\n",
    "\n",
    "labels = np.squeeze(labels)\n",
    "\n",
    "# sigma is more or less the radius of the gaussian we want to grow around each voxel - 10 voxels is a good bet\n",
    "# use an arbitrary voxel size of 1\n",
    "lsds = local_shape_descriptor.get_local_shape_descriptors(\n",
    "        segmentation=labels,\n",
    "        sigma=(10,)*2,\n",
    "        voxel_size=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to view unique labels with matplotlib \n",
    "\n",
    "def create_lut(labels):\n",
    "\n",
    "    max_label = np.max(labels)\n",
    "\n",
    "    lut = np.random.randint(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            size=(int(max_label + 1), 3),\n",
    "            dtype=np.uint64)\n",
    "\n",
    "    lut = np.append(\n",
    "            lut,\n",
    "            np.zeros(\n",
    "                (int(max_label + 1), 1),\n",
    "                dtype=np.uint8) + 255,\n",
    "            axis=1)\n",
    "\n",
    "    lut[0] = 0\n",
    "    colored_labels = lut[labels]\n",
    "\n",
    "    return colored_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9020df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "        2,\n",
    "        4,\n",
    "        figsize=(15, 8),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False)\n",
    "\n",
    "axes[0][0].imshow(np.squeeze(raw), cmap='gray')\n",
    "axes[0][0].set_title('raw')\n",
    "\n",
    "axes[0][1].imshow(create_lut(labels))\n",
    "axes[0][1].set_title('labels')\n",
    "\n",
    "axes[0][2].imshow(np.squeeze(lsds[0]), cmap='jet')\n",
    "axes[0][2].set_title('mean offset y')\n",
    "\n",
    "axes[0][3].imshow(np.squeeze(lsds[1]), cmap='jet')\n",
    "axes[0][3].set_title('mean offset x')\n",
    "\n",
    "axes[1][0].imshow(np.squeeze(lsds[2]), cmap='jet')\n",
    "axes[1][0].set_title('direction y')\n",
    "\n",
    "axes[1][1].imshow(np.squeeze(lsds[3]), cmap='jet')\n",
    "axes[1][1].set_title('direction x')\n",
    "\n",
    "axes[1][2].imshow(np.squeeze(lsds[4]), cmap='jet')\n",
    "axes[1][2].set_title('direction change xy')\n",
    "\n",
    "axes[1][3].imshow(np.squeeze(lsds[5]), cmap='jet')\n",
    "axes[1][3].set_title('size')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use gunpowder for our training and prediction pipelines\n",
    "# gunpowder is a library to facilitate machine learning on large, multi-dimensional arrays\n",
    "# it can make it easier to create pipelines and handle augmentations\n",
    "# here is a tutorial if you are interested in learning more: http://funkey.science/gunpowder/index.html\n",
    "\n",
    "import gunpowder as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1bd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for viewing our data with matplotlib\n",
    "\n",
    "def imshow(\n",
    "        raw=None,\n",
    "        ground_truth=None,\n",
    "        target=None,\n",
    "        prediction=None,\n",
    "        h=None,\n",
    "        shader='jet',\n",
    "        subplot=True,\n",
    "        channel=0,\n",
    "        target_name='target',\n",
    "        prediction_name='prediction'):\n",
    "\n",
    "    rows = 0\n",
    "\n",
    "    if raw is not None:\n",
    "        rows += 1\n",
    "        cols = raw.shape[0] if len(raw.shape) > 2 else 1\n",
    "    if ground_truth is not None:\n",
    "        rows += 1\n",
    "        cols = ground_truth.shape[0] if len(ground_truth.shape) > 2 else 1\n",
    "    if target is not None:\n",
    "        rows += 1\n",
    "        cols = target.shape[0] if len(target.shape) > 2 else 1\n",
    "    if prediction is not None:\n",
    "        rows += 1\n",
    "        cols = prediction.shape[0] if len(prediction.shape) > 2 else 1\n",
    "\n",
    "    if subplot:\n",
    "        fig, axes = plt.subplots(\n",
    "            rows,\n",
    "            cols,\n",
    "            figsize=(10, 4),\n",
    "            sharex=True,\n",
    "            sharey=True,\n",
    "            squeeze=False)\n",
    "\n",
    "    if h is not None:\n",
    "        fig.subplots_adjust(hspace=h)\n",
    "\n",
    "    def wrapper(data,row,name=\"raw\"):\n",
    "\n",
    "        if subplot:\n",
    "            if len(data.shape) == 2:\n",
    "                if name == 'raw':\n",
    "                    axes[0][0].imshow(data, cmap='gray')\n",
    "                    axes[0][0].set_title(name)\n",
    "                else:\n",
    "                    axes[row][0].imshow(create_lut(data))\n",
    "                    axes[row][0].set_title(name)\n",
    "\n",
    "            elif len(data.shape) == 3:\n",
    "                for i, im in enumerate(data):\n",
    "                    if name == 'raw':\n",
    "                        axes[0][i].imshow(im, cmap='gray')\n",
    "                        axes[0][i].set_title(name)\n",
    "                    else:\n",
    "                        axes[row][i].imshow(create_lut(im))\n",
    "                        axes[row][i].set_title(name)\n",
    "\n",
    "            else:\n",
    "                for i, im in enumerate(data):\n",
    "                    axes[row][i].imshow(im[channel], cmap=shader)\n",
    "                    axes[row][i].set_title(name)\n",
    "\n",
    "        else:\n",
    "            if name == 'raw':\n",
    "                plt.imshow(data, cmap='gray')\n",
    "            if name == 'labels':\n",
    "                plt.imshow(data, alpha=0.5)\n",
    "\n",
    "    row=0 \n",
    "\n",
    "    if raw is not None:\n",
    "        wrapper(raw,row=row)\n",
    "        row += 1\n",
    "    if ground_truth is not None:\n",
    "        wrapper(ground_truth,row=row,name='labels')\n",
    "        row += 1\n",
    "    if target is not None:\n",
    "        wrapper(target,row=row,name=target_name)\n",
    "        row += 1\n",
    "    if prediction is not None:\n",
    "        wrapper(prediction,row=row,name=prediction_name)\n",
    "        row += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gunpowder local shape descriptor node\n",
    "\n",
    "from lsd.gp import AddLocalShapeDescriptor\n",
    "import math\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4eda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gunpowder class to convert our labels data dtype (lsd node assumes np.uint64 but our labels data is np.uint16)\n",
    "\n",
    "class ConvertLabels(gp.BatchFilter):\n",
    "\n",
    "    def __init__(self, in_array, out_array, dtype):\n",
    "        self.in_array = in_array\n",
    "        self.out_array = out_array\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.provides(\n",
    "            self.out_array,\n",
    "            self.spec[self.in_array].copy())\n",
    "        \n",
    "    def prepare(self, request):\n",
    "\n",
    "        deps = gp.BatchRequest()\n",
    "        deps[self.in_array] = request[self.out_array].copy()\n",
    "\n",
    "        return deps\n",
    "\n",
    "    def process(self, batch, request):\n",
    "\n",
    "        data = batch[self.in_array].data.astype(self.dtype)\n",
    "\n",
    "        spec = batch[self.in_array].spec.copy()\n",
    "        spec.roi = request[self.out_array].roi.copy()\n",
    "        spec.dtype = self.dtype\n",
    "\n",
    "        batch = gp.Batch()\n",
    "\n",
    "        array = gp.Array(data, spec)\n",
    "\n",
    "        batch[self.out_array] = array\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training pipeline\n",
    "# no training for now, let's just create our lsds and affinities and see how to implement some things in gunpowder\n",
    "\n",
    "def train(\n",
    "    iterations,\n",
    "    show_every,\n",
    "    batch_size,\n",
    "    show_gt=True,\n",
    "    show_pred=False,\n",
    "    lsd_channels=None,\n",
    "    aff_channels=None):\n",
    "    \n",
    "    # set arbitrary voxel size\n",
    "    voxel_size = gp.Coordinate((1,)*2)\n",
    "    \n",
    "    # input and output size of our network (in voxels)\n",
    "    input_size = gp.Coordinate((136,)*2)\n",
    "    output_size = gp.Coordinate((96,)*2)\n",
    "        \n",
    "    # we will use valid padding so the context of our network will come in handy when writing data\n",
    "    context = (input_size - output_size) /2\n",
    "     \n",
    "    # create some keys to keep track of our data\n",
    "    raw = gp.ArrayKey('RAW')\n",
    "    labels = gp.ArrayKey('LABELS')\n",
    "    converted_labels = gp.ArrayKey('CONVERTED_LABELS')\n",
    "    gt_lsds = gp.ArrayKey('GT_LSDS')\n",
    "    gt_affs = gp.ArrayKey('GT_AFFS')\n",
    "   \n",
    "    # create a request to map our data to our patch sizes. The request behaves like a dictionary\n",
    "    # mapping each array key to a region of interest (ROI), i.e., an offset and a size.\n",
    "    request = gp.BatchRequest()\n",
    "\n",
    "    # add our data to the request\n",
    "    request.add(raw, input_size)\n",
    "    request.add(labels, output_size)\n",
    "    request.add(converted_labels, output_size)\n",
    "    request.add(gt_lsds, output_size)\n",
    "    request.add(gt_affs, output_size)\n",
    "        \n",
    "    # get our training files\n",
    "    files = glob.glob(os.path.join(\"data_epithelia\", \"train\", \"*.zarr\"))\n",
    "\n",
    "    # create a tuple of sources. for each source we will normalize the raw data\n",
    "    # pad, and request a random location (equal to our input size - handled by the request)\n",
    "    sources = tuple(\n",
    "        gp.ZarrSource(\n",
    "            sample,  \n",
    "            {\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/gt_labels'\n",
    "            },  \n",
    "            {\n",
    "                raw: gp.ArraySpec(interpolatable=True, voxel_size=voxel_size),\n",
    "                labels: gp.ArraySpec(interpolatable=False, voxel_size=voxel_size)\n",
    "            }) + \n",
    "            gp.Normalize(raw) +\n",
    "            gp.Pad(raw, None) +\n",
    "            gp.Pad(labels, context) +\n",
    "            gp.RandomLocation()\n",
    "            for sample in files\n",
    "        )\n",
    "\n",
    "    # right now our data has these shapes and dtypes:\n",
    "    # raw: (1, h, w)\n",
    "    # labels: (1, h, w) (dtype = np.uint16)\n",
    "\n",
    "    # create a pipeline from our sources\n",
    "    pipeline = sources\n",
    "\n",
    "    # randomly choose a sample\n",
    "    pipeline += gp.RandomProvider()\n",
    "    \n",
    "    # random mirror / transpose the batch\n",
    "    pipeline += gp.SimpleAugment()\n",
    "\n",
    "    # elastically deform \n",
    "    pipeline += gp.ElasticAugment(\n",
    "        control_point_spacing=(32, 32),\n",
    "        jitter_sigma=(5.0, 5.0),\n",
    "        rotation_interval=(0, math.pi/2))\n",
    "\n",
    "    # randomly scale the raw intensity\n",
    "    pipeline += gp.IntensityAugment(\n",
    "        raw,\n",
    "        scale_min=0.9,\n",
    "        scale_max=1.1,\n",
    "        shift_min=-0.1,\n",
    "        shift_max=0.1)\n",
    "    \n",
    "    # remove channel dim from labels so we can calculate lsds on them\n",
    "    pipeline += gp.Squeeze([labels])\n",
    "    \n",
    "    # new shapes:\n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w) (dtype = np.uint16)\n",
    "    \n",
    "    # convert labels to np.uint64, write to a new array (converted_labels)\n",
    "    pipeline += ConvertLabels(\n",
    "        labels,\n",
    "        converted_labels,\n",
    "        np.uint64)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w) (dtype = np.uint64)\n",
    "        \n",
    "    # calculate lsds\n",
    "    pipeline += AddLocalShapeDescriptor(\n",
    "        converted_labels,\n",
    "        gt_lsds,\n",
    "        sigma=10,\n",
    "        downsample=1)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    \n",
    "    # add affinities (nearest neighbor affinities so single voxel neighborhood in 2d)\n",
    "    pipeline += gp.AddAffinities(\n",
    "        affinity_neighborhood=[\n",
    "            [0, -1],\n",
    "            [-1, 0]],\n",
    "        labels=converted_labels,\n",
    "        affinities=gt_affs,\n",
    "        dtype=np.float32)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    # gt_affs: (2, h, w)\n",
    "\n",
    "    # add a channel dim back to labels\n",
    "    pipeline += gp.Unsqueeze([converted_labels])\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (1, h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    # gt_affs: (2, h, w) \n",
    "\n",
    "    # stack batch size\n",
    "    pipeline += gp.Stack(batch_size)\n",
    "\n",
    "    # raw: (b, 1, h, w)\n",
    "    # labels: (b, 1, h, w)\n",
    "    # gt_lsds: (b, 6, h, w)\n",
    "    # gt_affs: (b, 2, h, w) \n",
    "    \n",
    "    # build pipeline\n",
    "    with gp.build(pipeline):\n",
    "        for i in range(iterations):\n",
    "            batch = pipeline.request_batch(request)\n",
    "\n",
    "            # crop raw data to labels roi for matplotlib \n",
    "            start = request[converted_labels].roi.get_begin()/voxel_size\n",
    "            end = request[converted_labels].roi.get_end()/voxel_size\n",
    "\n",
    "            # every nth iteration, show a batch\n",
    "            if i % show_every == 0:\n",
    "              \n",
    "                imshow(raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]]))\n",
    "                imshow(ground_truth=batch[converted_labels].data)\n",
    "            \n",
    "                if lsd_channels:\n",
    "                    for n,c in lsd_channels.items():\n",
    "                        if show_gt:\n",
    "                            imshow(target=batch[gt_lsds].data, target_name='gt '+n, channel=c)\n",
    "                        if show_pred:\n",
    "                            imshow(prediction=batch[pred_lsds].data, prediction_name='pred '+n, channel=c)\n",
    "\n",
    "                if aff_channels:\n",
    "                    for n,c in aff_channels.items():\n",
    "                        if show_gt:\n",
    "                            imshow(target=batch[gt_affs].data, target_name='gt '+n, channel=c)\n",
    "                        if show_pred:\n",
    "                            imshow(target=batch[pred_affs].data, target_name='pred '+n, channel=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a batch of ground truth lsds/affs, no need to show predicted lsds/affs yet\n",
    "\n",
    "lsd_channels = {\n",
    "    'offset (y)': 0,\n",
    "    'offset (x)': 1,\n",
    "    'orient (y)': 2,\n",
    "    'orient (x)': 3,\n",
    "    'yx change': 4,\n",
    "    'voxel count': 5\n",
    "}\n",
    "\n",
    "aff_channels = {'affs y': 0, 'affs x': 1}\n",
    "\n",
    "train(\n",
    "    iterations=1,\n",
    "    show_every=1,\n",
    "    batch_size=5,\n",
    "    lsd_channels=lsd_channels,\n",
    "    aff_channels=aff_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use this library for our unet model\n",
    "from funlib.learn.torch.models import UNet, ConvPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multi task lsd + affs model\n",
    "# this is the idea behind the MTLSD model in the lsd paper\n",
    "# we have two output heads of the unet (one for lsd and one for affs)\n",
    "# we combine their losses and then minimize during training\n",
    "\n",
    "class MtlsdModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        num_fmaps=12\n",
    "        \n",
    "        ds_fact = [(2,2),(2,2),(2,2)]\n",
    "        num_levels = len(ds_fact) + 1\n",
    "        ksd = [[(3,3), (3,3)]]*num_levels\n",
    "        ksu = [[(3,3), (3,3)]]*(num_levels - 1)\n",
    "\n",
    "        self.unet = UNet(\n",
    "            in_channels=1,\n",
    "            num_fmaps=num_fmaps,\n",
    "            fmap_inc_factor=5,\n",
    "            downsample_factors=ds_fact,\n",
    "            kernel_size_down=ksd,\n",
    "            kernel_size_up=ksu)\n",
    "        \n",
    "        # need 6 output channels (lsd on 2d data is 6 dimensional)\n",
    "        # LSD[0:1] = mean offset in y\n",
    "        # LSD[1:2] = mean offset in x\n",
    "        # LSD[2:3] = orientation in y\n",
    "        # LSD[3:4] = orientation in x\n",
    "        # LSD[4:5] = change in orientation y-x\n",
    "        # LSD[5:6] = size (voxel count)\n",
    "        \n",
    "        # and 2 for affs (x and y affinities in this case)\n",
    "\n",
    "        self.lsd_head = ConvPass(num_fmaps, 6, [[1, 1]], activation='Sigmoid')\n",
    "        self.aff_head = ConvPass(num_fmaps, 2, [[1, 1]], activation='Sigmoid')\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        z = self.unet(input)\n",
    "        lsds = self.lsd_head(z)\n",
    "        affs = self.aff_head(z)\n",
    "\n",
    "        return lsds, affs\n",
    "\n",
    "# combine the lsds and affs losses\n",
    "# use weighted loss for each (just multiply predictions and targets by weights)\n",
    "class WeightedMSELoss(torch.nn.MSELoss):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, lsds_prediction, lsds_target, lsds_weights, affs_prediction, affs_target, affs_weights,):\n",
    "\n",
    "        loss1 = super(WeightedMSELoss, self).forward(\n",
    "                lsds_prediction*lsds_weights,\n",
    "                lsds_target*lsds_weights)\n",
    "\n",
    "        loss2 = super(WeightedMSELoss, self).forward(\n",
    "            affs_prediction*affs_weights,\n",
    "            affs_target*affs_weights)\n",
    "        \n",
    "        return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a train node (this is a wrapper around the zero_grad, backward, step functions you have become familiar with)\n",
    "from gunpowder.torch import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c900b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add train node and associated keys to pipeline\n",
    "def train(\n",
    "    iterations,\n",
    "    show_every,\n",
    "    batch_size,\n",
    "    show_gt=True,\n",
    "    show_pred=False,\n",
    "    lsd_channels=None,\n",
    "    aff_channels=None):\n",
    "    \n",
    "    voxel_size = gp.Coordinate((1,)*2)\n",
    "    \n",
    "    input_size = gp.Coordinate((172,)*2)\n",
    "    output_size = gp.Coordinate((80,)*2)\n",
    "        \n",
    "    context = (input_size - output_size) /2\n",
    "        \n",
    "    raw = gp.ArrayKey('RAW')\n",
    "    labels = gp.ArrayKey('LABELS')\n",
    "    converted_labels = gp.ArrayKey('CONVERTED_LABELS')\n",
    "    gt_lsds = gp.ArrayKey('GT_LSDS')\n",
    "    lsds_weights = gp.ArrayKey('LSDS_WEIGHTS')\n",
    "    pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
    "    gt_affs = gp.ArrayKey('GT_AFFS')\n",
    "    affs_weights = gp.ArrayKey('AFFS_WEIGHTS')\n",
    "    pred_affs = gp.ArrayKey('PRED_AFFS')\n",
    "    \n",
    "    request = gp.BatchRequest()\n",
    "\n",
    "    request.add(raw, input_size)\n",
    "    request.add(labels, output_size)\n",
    "    request.add(converted_labels, output_size)\n",
    "    request.add(gt_lsds, output_size)\n",
    "    request.add(lsds_weights, output_size)\n",
    "    request.add(pred_lsds, output_size)\n",
    "    request.add(gt_affs, output_size)\n",
    "    request.add(affs_weights, output_size)\n",
    "    request.add(pred_affs, output_size)\n",
    "    \n",
    "    # get model, loss, optimizer\n",
    "    model = MtlsdModel()\n",
    "    loss = WeightedMSELoss()\n",
    "    optimizer = torch.optim.Adam(lr=0.5e-4, params=model.parameters())\n",
    "        \n",
    "    files = glob.glob(os.path.join(\"data_epithelia\", \"train\", \"*.zarr\"))\n",
    "\n",
    "    sources = tuple(\n",
    "        gp.ZarrSource(\n",
    "            sample,  \n",
    "            {\n",
    "                raw: 'volumes/raw',\n",
    "                labels: 'volumes/gt_labels'\n",
    "            },  \n",
    "            {\n",
    "                raw: gp.ArraySpec(interpolatable=True, voxel_size=voxel_size),\n",
    "                labels: gp.ArraySpec(interpolatable=False, voxel_size=voxel_size)\n",
    "            }) + \n",
    "            gp.Normalize(raw) +\n",
    "            gp.Pad(raw, None) +\n",
    "            gp.Pad(labels, context) +\n",
    "            gp.RandomLocation()\n",
    "            for sample in files\n",
    "        )\n",
    "\n",
    "    # raw: (1, h, w)\n",
    "    # labels: (1, h, w) (dtype = np.uint16)\n",
    "\n",
    "    pipeline = sources\n",
    "\n",
    "    pipeline += gp.RandomProvider()\n",
    "    \n",
    "    pipeline += gp.SimpleAugment()\n",
    "\n",
    "    pipeline += gp.ElasticAugment(\n",
    "        control_point_spacing=(32, 32),\n",
    "        jitter_sigma=(5.0, 5.0),\n",
    "        rotation_interval=(0, math.pi/2))\n",
    "\n",
    "    pipeline += gp.IntensityAugment(\n",
    "        raw,\n",
    "        scale_min=0.9,\n",
    "        scale_max=1.1,\n",
    "        shift_min=-0.1,\n",
    "        shift_max=0.1)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (1, h, w) (dtype = np.uint16)\n",
    "            \n",
    "    pipeline += gp.Squeeze([labels])\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w) (dtype = np.uint16)\n",
    "    \n",
    "    pipeline += ConvertLabels(\n",
    "        labels,\n",
    "        converted_labels,\n",
    "        np.uint64)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (1, h, w) (dtype = np.uint64)\n",
    "    \n",
    "    # erode the boundaries between labels, we want the network to learn what to do in between the labels\n",
    "    pipeline += gp.GrowBoundary(converted_labels)\n",
    "        \n",
    "    pipeline += AddLocalShapeDescriptor(\n",
    "        converted_labels,\n",
    "        gt_lsds,\n",
    "        mask=lsds_weights,\n",
    "        sigma=10,\n",
    "        downsample=1)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    # lsds_weights: (6, h, w)\n",
    "    \n",
    "    pipeline += gp.AddAffinities(\n",
    "        affinity_neighborhood=[\n",
    "            [0, -1],\n",
    "            [-1, 0]],\n",
    "        labels=converted_labels,\n",
    "        affinities=gt_affs,\n",
    "        dtype=np.float32)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    # lsds_weights: (6, h, w)\n",
    "    # gt_affs: (2, h, w)\n",
    "    \n",
    "    # create a weights array for our affs\n",
    "    pipeline += gp.BalanceLabels(\n",
    "        gt_affs,\n",
    "        affs_weights)\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    # lsds_weights: (6, h, w)\n",
    "    # gt_affs: (2, h, w)\n",
    "    # affs_weights: (2, h, w)\n",
    "\n",
    "    pipeline += gp.Unsqueeze([converted_labels])\n",
    "    \n",
    "    # raw: (1, h, w)\n",
    "    # labels: (1, h, w)\n",
    "    # gt_lsds: (6, h, w)\n",
    "    # lsds_weights: (6, h, w)\n",
    "    # gt_affs: (2, h, w)\n",
    "    # affs_weights: (2, h, w)\n",
    "\n",
    "    pipeline += gp.Stack(batch_size)\n",
    "\n",
    "    # raw: (b, 1, h, w)\n",
    "    # labels: (b, 1, h, w)\n",
    "    # gt_lsds: (b, 6, h, w)\n",
    "    # lsds_weights: (b, 6, h, w)\n",
    "    # gt_affs: (b, 2, h, w)\n",
    "    # affs_weights: (b, 2, h, w)\n",
    "    \n",
    "    # pass everything to our train node\n",
    "    pipeline += Train(\n",
    "        model,\n",
    "        loss,\n",
    "        optimizer,\n",
    "        inputs={\n",
    "            'input': raw\n",
    "        },\n",
    "        outputs={\n",
    "            0: pred_lsds,\n",
    "            1: pred_affs\n",
    "        },\n",
    "        loss_inputs={\n",
    "            0: pred_lsds,\n",
    "            1: gt_lsds,\n",
    "            2: lsds_weights,\n",
    "            3: pred_affs,\n",
    "            4: gt_affs,\n",
    "            5: affs_weights\n",
    "        })\n",
    "    \n",
    "    # raw: (b, 1, h, w)\n",
    "    # labels: (b, 1, h, w)\n",
    "    # gt_lsds: (b, 6, h, w)\n",
    "    # lsds_weights: (b, 6, h, w)\n",
    "    # gt_affs: (b, 2, h, w)\n",
    "    # affs_weights: (b, 2, h, w)\n",
    "    # pred_lsds: (b, 6, h, w)\n",
    "    # pred_affs: (b, 2, h, w)\n",
    "    \n",
    "    with gp.build(pipeline):\n",
    "        for i in range(iterations):\n",
    "            batch = pipeline.request_batch(request)\n",
    "\n",
    "            start = request[converted_labels].roi.get_begin()/voxel_size\n",
    "            end = request[converted_labels].roi.get_end()/voxel_size\n",
    "\n",
    "            if i % show_every == 0:\n",
    "              \n",
    "                imshow(raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]]))\n",
    "                imshow(ground_truth=batch[converted_labels].data)\n",
    "            \n",
    "                if lsd_channels:\n",
    "                    for n,c in lsd_channels.items():\n",
    "                        if show_gt:\n",
    "                            imshow(target=batch[gt_lsds].data, target_name='gt '+n, channel=c)\n",
    "                        if show_pred:\n",
    "                            imshow(prediction=batch[pred_lsds].data, prediction_name='pred '+n, channel=c)\n",
    "\n",
    "                if aff_channels:\n",
    "                    for n,c in aff_channels.items():\n",
    "                        if show_gt:\n",
    "                            imshow(target=batch[gt_affs].data, target_name='gt '+n, channel=c)\n",
    "                        if show_pred:\n",
    "                            imshow(target=batch[pred_affs].data, target_name='pred '+n, channel=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions now. \n",
    "# feel free to train for longer - it will couple thousand iterations for the predictions to improve\n",
    "# we will just use a pre-trained network for inference\n",
    "\n",
    "train(\n",
    "    iterations=2000,\n",
    "    show_every=100,\n",
    "    batch_size=5,\n",
    "    show_pred=True,\n",
    "    lsd_channels=lsd_channels,\n",
    "    aff_channels=aff_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de5412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this library has some nice wrappers for data loading and cropping rois\n",
    "import daisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = gp.Coordinate((1,)*2)\n",
    "    \n",
    "input_size = gp.Coordinate((172,)*2)\n",
    "output_size = gp.Coordinate((80,)*2)\n",
    "\n",
    "context = (input_size - output_size) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ba44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a predict pipeline (this is also known as inference)\n",
    "def predict(\n",
    "    checkpoint,\n",
    "    raw_file,\n",
    "    raw_dataset,\n",
    "    labels_dataset,\n",
    "    out_file,\n",
    "    out_datasets):\n",
    "    \n",
    "    raw = gp.ArrayKey('RAW')\n",
    "    labels = gp.ArrayKey('LABELS')\n",
    "    pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
    "    pred_affs = gp.ArrayKey('PRED_AFFS')\n",
    "\n",
    "    # create a scan request. we will tile over our full raw image size in patches of our network size\n",
    "    scan_request = gp.BatchRequest()\n",
    "\n",
    "    scan_request.add(raw, input_size)\n",
    "    scan_request.add(labels, input_size)\n",
    "    scan_request.add(pred_lsds, output_size)\n",
    "    scan_request.add(pred_affs, output_size)\n",
    "\n",
    "    source = gp.ZarrSource(\n",
    "        raw_file,\n",
    "            {\n",
    "                raw: raw_dataset,\n",
    "                labels: labels_dataset\n",
    "            },\n",
    "            {\n",
    "                raw: gp.ArraySpec(interpolatable=True, voxel_size=voxel_size),\n",
    "                labels: gp.ArraySpec(interpolatable=True, voxel_size=voxel_size)\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # since our network uses valid convolutions, our network output size is smaller than our input size\n",
    "    # but we want to evaluate on the full image.\n",
    "    # so we need to grow the input by the context of the network and pad our data\n",
    "    \n",
    "    with gp.build(source):\n",
    "        total_input_roi = source.spec[raw].roi.grow(context, context)\n",
    "        total_output_roi = source.spec[raw].roi\n",
    "        \n",
    "    source += gp.Pad(raw, context)\n",
    "    source += gp.Pad(labels, context)\n",
    "        \n",
    "    # create empty zarr datasets to write our data to\n",
    "    for ds in out_datasets:\n",
    "        if 'lsd' in ds:\n",
    "            dims=6\n",
    "        elif 'affs' in ds:\n",
    "            dims=2\n",
    "        else:\n",
    "            dims=1\n",
    "            \n",
    "        dtype = np.uint64 if 'labels' in ds else np.float32\n",
    "        \n",
    "        daisy.prepare_ds(\n",
    "                out_file,\n",
    "                ds,\n",
    "                daisy.Roi(\n",
    "                    total_output_roi.get_offset(),\n",
    "                    total_output_roi.get_shape()\n",
    "                ),\n",
    "                voxel_size,\n",
    "                write_size=output_size,\n",
    "                num_channels=dims,\n",
    "                dtype=dtype)\n",
    "\n",
    "    model = MtlsdModel()\n",
    "\n",
    "    # set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # add a predict node\n",
    "    predict = gp.torch.Predict(\n",
    "        model=model,\n",
    "        checkpoint=checkpoint,\n",
    "        inputs = {\n",
    "            'input': raw\n",
    "        },\n",
    "        outputs = {\n",
    "            0: pred_lsds,\n",
    "            1: pred_affs}\n",
    "        )\n",
    "    \n",
    "    # this will scan in chunks equal to the input/output sizes of the respective arrays\n",
    "    scan = gp.Scan(scan_request)\n",
    "\n",
    "    # write out data\n",
    "    write = gp.ZarrWrite(\n",
    "        dataset_names={\n",
    "            raw: 'raw',\n",
    "            labels: 'labels',\n",
    "            pred_lsds: 'pred_lsds',\n",
    "            pred_affs: 'pred_affs'},\n",
    "        output_filename=out_file)\n",
    "    \n",
    "    pipeline = source\n",
    "    pipeline += gp.Normalize(raw)\n",
    "    \n",
    "    # only need a batch size of 1 for prediction\n",
    "    pipeline += gp.Stack(1)\n",
    "    pipeline += predict\n",
    "    pipeline += scan\n",
    "    \n",
    "    # remove batch dim from raw and labels\n",
    "    pipeline += gp.Squeeze([raw, labels])\n",
    "    \n",
    "    # remove channel dim from raw, labels and batch dim from pred lsds / pred_affs\n",
    "    pipeline += gp.Squeeze(\n",
    "        [raw,\n",
    "         labels,\n",
    "         pred_lsds,\n",
    "         pred_affs])\n",
    "    pipeline += write\n",
    "\n",
    "    # we have another request for the full roi we are scanning over\n",
    "    predict_request = gp.BatchRequest()\n",
    "\n",
    "    # this lets us know to process the full image. we will scan over it until it is done\n",
    "    predict_request[raw] = total_input_roi\n",
    "    predict_request[labels] = total_input_roi\n",
    "    predict_request[pred_lsds] = total_output_roi\n",
    "    predict_request[pred_affs] = total_output_roi\n",
    "\n",
    "    with gp.build(pipeline):\n",
    "        pipeline.request_batch(predict_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aea8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all our testing data\n",
    "test_files = glob.glob(os.path.join(\"data_epithelia\", \"test\", \"*.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch a pretrained model checkpoint\n",
    "!wget https://www.dropbox.com/s/2avnabaftjwqqgs/model_checkpoint_10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c402fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint and predict on a random image from the test set\n",
    "checkpoint = 'model_checkpoint_10000' \n",
    "raw_file = test_files[random.randint(0,len(test_files)-1)]\n",
    "raw_dataset = 'volumes/raw'\n",
    "labels_dataset = 'volumes/gt_labels'\n",
    "out_file = 'prediction.zarr'\n",
    "out_datasets = ['raw', 'labels', 'pred_lsds', 'pred_affs']\n",
    "\n",
    "predict(\n",
    "    checkpoint,\n",
    "    raw_file,\n",
    "    raw_dataset,\n",
    "    labels_dataset,\n",
    "    out_file,\n",
    "    out_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data to visualize\n",
    "pred_f = zarr.open('prediction.zarr')\n",
    "test_raw = pred_f['raw'][:]\n",
    "test_labels = pred_f['labels'][:].astype(np.uint64)\n",
    "test_lsds = pred_f['pred_lsds'][:]\n",
    "test_affs = pred_f['pred_affs'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807431f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "        1,\n",
    "        4,\n",
    "        figsize=(15, 8),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False)\n",
    "\n",
    "axes[0][0].imshow(test_raw, cmap='gray')\n",
    "axes[0][0].set_title('raw')\n",
    "\n",
    "axes[0][1].imshow(create_lut(test_labels))\n",
    "axes[0][1].set_title('labels')\n",
    "\n",
    "axes[0][2].imshow(np.squeeze(test_lsds[0]), cmap='jet')\n",
    "axes[0][2].imshow(np.squeeze(test_lsds[1]), cmap='jet', alpha=0.5)\n",
    "axes[0][2].set_title('predicted offset vectors')\n",
    "\n",
    "axes[0][3].imshow(np.squeeze(test_affs[0] + test_affs[1]), cmap='jet')\n",
    "axes[0][3].set_title('predicted affinities')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214eb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to relabel connected components\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use daisy to load our data because it is easier to crop data to a specific roi\n",
    "# in this case we want to crop a few pixels of the edge of our image\n",
    "# because of border artifacts from prediction (bc of valid convolutions)\n",
    "\n",
    "raw = daisy.open_ds('prediction.zarr', 'raw')\n",
    "labels = daisy.open_ds('prediction.zarr', 'labels')\n",
    "lsds = daisy.open_ds('prediction.zarr', 'pred_lsds')\n",
    "affs =  daisy.open_ds('prediction.zarr', 'pred_affs')\n",
    "\n",
    "# crop a little off the edges \n",
    "crop = gp.Coordinate((8,)*2)\n",
    "roi = raw.roi.grow(-crop, -crop)\n",
    "\n",
    "# intersect with roi and convert to numpy array\n",
    "raw = raw[roi].to_ndarray()\n",
    "labels = labels[roi].to_ndarray()\n",
    "lsds = lsds[roi].to_ndarray()\n",
    "affs = affs[roi].to_ndarray()\n",
    "\n",
    "# remember to relabel gt since we cropped it\n",
    "labels, _ = label(labels)\n",
    "labels = labels.astype(np.uint64)\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "        1,\n",
    "        4,\n",
    "        figsize=(15, 8),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False)\n",
    "\n",
    "axes[0][0].imshow(raw, cmap='gray')\n",
    "axes[0][0].set_title('raw')\n",
    "\n",
    "axes[0][1].imshow(create_lut(labels))\n",
    "axes[0][1].set_title('labels')\n",
    "\n",
    "axes[0][2].imshow(np.squeeze(lsds[0]), cmap='jet')\n",
    "axes[0][2].imshow(np.squeeze(lsds[1]), cmap='jet', alpha=0.5)\n",
    "axes[0][2].set_title('predicted offset vectors')\n",
    "\n",
    "axes[0][3].imshow(np.squeeze(affs[0] + affs[1]), cmap='jet')\n",
    "axes[0][3].set_title('predicted affinities')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these libraries will be useful for performing watershed and getting a segmentation\n",
    "\n",
    "import waterz\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47810200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions to get supervoxels (fragments) from affinities\n",
    "\n",
    "def watershed_from_boundary_distance(\n",
    "        boundary_distances,\n",
    "        boundary_mask,\n",
    "        return_seeds=False,\n",
    "        id_offset=0,\n",
    "        min_seed_distance=10):\n",
    "\n",
    "    max_filtered = maximum_filter(boundary_distances, min_seed_distance)\n",
    "    maxima = max_filtered==boundary_distances\n",
    "    seeds, n = label(maxima)\n",
    "\n",
    "    print(f\"Found {n} fragments\")\n",
    "\n",
    "    if n == 0:\n",
    "        return np.zeros(boundary_distances.shape, dtype=np.uint64), id_offset\n",
    "\n",
    "    seeds[seeds!=0] += id_offset\n",
    "\n",
    "    fragments = watershed(\n",
    "        boundary_distances.max() - boundary_distances,\n",
    "        seeds,\n",
    "        mask=boundary_mask)\n",
    "\n",
    "    ret = (fragments.astype(np.uint64), n + id_offset)\n",
    "    if return_seeds:\n",
    "        ret = ret + (seeds.astype(np.uint64),)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def watershed_from_affinities(\n",
    "        affs,\n",
    "        max_affinity_value=1.0,\n",
    "        fragments_in_xy=True,\n",
    "        return_seeds=False,\n",
    "        min_seed_distance=10,\n",
    "        labels_mask=None):\n",
    "\n",
    "    mean_affs = 0.5*(affs[1] + affs[2])\n",
    "    depth = mean_affs.shape[0]\n",
    "\n",
    "    fragments = np.zeros(mean_affs.shape, dtype=np.uint64)\n",
    "    if return_seeds:\n",
    "        seeds = np.zeros(mean_affs.shape, dtype=np.uint64)\n",
    "\n",
    "    id_offset = 0\n",
    "\n",
    "    for z in range(depth):\n",
    "\n",
    "        boundary_mask = mean_affs[z]>0.5*max_affinity_value\n",
    "        boundary_distances = distance_transform_edt(boundary_mask)\n",
    "\n",
    "        if labels_mask is not None:\n",
    "\n",
    "            boundary_mask *= labels_mask.astype(bool)\n",
    "\n",
    "        ret = watershed_from_boundary_distance(\n",
    "            boundary_distances,\n",
    "            boundary_mask,\n",
    "            return_seeds=return_seeds,\n",
    "            id_offset=id_offset,\n",
    "            min_seed_distance=min_seed_distance)\n",
    "\n",
    "        fragments[z] = ret[0]\n",
    "        if return_seeds:\n",
    "            seeds[z] = ret[2]\n",
    "\n",
    "        id_offset = ret[1]\n",
    "\n",
    "    ret = (fragments, id_offset)\n",
    "    if return_seeds:\n",
    "        ret += (seeds,)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ef9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to agglomerate fragments using underlying affinities as edge weights\n",
    "# returns a segmentation from a final threshold\n",
    "\n",
    "def get_segmentation(affinities, threshold, labels_mask=None):\n",
    "\n",
    "    fragments = watershed_from_affinities(\n",
    "            affinities,\n",
    "            labels_mask=labels_mask)[0]\n",
    "\n",
    "    thresholds = [threshold]\n",
    "\n",
    "    generator = waterz.agglomerate(\n",
    "        affs=affinities.astype(np.float32),\n",
    "        fragments=fragments,\n",
    "        thresholds=thresholds,\n",
    "    )\n",
    "\n",
    "    segmentation = next(generator)\n",
    "\n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39378676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed assumes 3d arrays, create fake channel dim\n",
    "affs = np.stack([\n",
    "    np.zeros_like(affs[0]),\n",
    "    affs[0],\n",
    "    affs[1]]\n",
    ")\n",
    "\n",
    "# waterz agglomerate requires 4d affs (c, d, h, w) - add fake z dim\n",
    "affs = np.expand_dims(affs, axis=1)\n",
    "\n",
    "#just test a 0.5 threshold. higher thresholds will merge more, lower thresholds will split more\n",
    "threshold = 0.5\n",
    "\n",
    "segmentation = get_segmentation(affs, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is useful for removing small holes in an array\n",
    "from skimage.morphology import remove_small_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove small holes and relabel connected components\n",
    "seg, _ = label(\n",
    "        remove_small_holes(\n",
    "                segmentation.astype(bool),\n",
    "                area_threshold=256))\n",
    "\n",
    "seg = seg.astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "        1,\n",
    "        3,\n",
    "        figsize=(15, 8),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False)\n",
    "\n",
    "axes[0][0].imshow(raw, cmap='gray')\n",
    "axes[0][0].set_title('raw')\n",
    "\n",
    "axes[0][1].imshow(create_lut(labels))\n",
    "axes[0][1].set_title('labels')\n",
    "\n",
    "axes[0][2].imshow(create_lut(np.squeeze(seg)))\n",
    "axes[0][2].set_title('segmentation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8af4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this package has a useful function for eroding boundaries\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec77f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to erode the ground truth boundaries before we evaluate \n",
    "def erode_boundaries(\n",
    "        labels,\n",
    "        iterations=1,\n",
    "        border_value=1):\n",
    "\n",
    "    foreground = np.zeros(shape=labels.shape, dtype=bool)\n",
    "\n",
    "    for label in np.unique(labels):\n",
    "        if label == 0:\n",
    "            continue\n",
    "\n",
    "        label_mask = labels ==label\n",
    "\n",
    "        eroded_label_mask = ndimage.binary_erosion(label_mask, iterations=iterations, border_value=border_value)\n",
    "        foreground = np.logical_or(eroded_label_mask, foreground)\n",
    "\n",
    "    background = np.logical_not(foreground)\n",
    "    labels[background] = 0\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create eroded labels\n",
    "eroded_labels = erode_boundaries(labels, iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238493b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "        1,\n",
    "        3,\n",
    "        figsize=(15, 8),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False)\n",
    "\n",
    "axes[0][0].imshow(raw, cmap='gray')\n",
    "axes[0][0].set_title('raw')\n",
    "\n",
    "axes[0][1].imshow(create_lut(eroded_labels))\n",
    "axes[0][1].set_title('eroded labels')\n",
    "\n",
    "axes[0][2].imshow(create_lut(np.squeeze(seg)))\n",
    "axes[0][2].set_title('segmentation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get util function for evaluation\n",
    "from utils.evaluate import evaluate_linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef416d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics for this image\n",
    "ap, precision, recall, tp, fp, fn = evaluate_linear_sum_assignment(seg,eroded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da112a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ap, precision, recall, tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce52b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do it for all images and get the averages for the metrics\n",
    "\n",
    "avg_ap = 0.0\n",
    "avg_precision = 0.0\n",
    "avg_recall = 0.0\n",
    "avg_tp = 0.0\n",
    "avg_fp = 0.0\n",
    "avg_fn = 0.0\n",
    "\n",
    "for index, f in enumerate(test_files):\n",
    "    \n",
    "    print(f'running prediction on {f}')\n",
    "        \n",
    "    out_file = f'prediction_{index}.zarr'\n",
    "\n",
    "    predict(\n",
    "        checkpoint,\n",
    "        f,\n",
    "        raw_dataset,\n",
    "        labels_dataset,\n",
    "        out_file,\n",
    "        out_datasets)\n",
    "    \n",
    "    raw = daisy.open_ds(out_file, 'raw')\n",
    "    labels = daisy.open_ds(out_file, 'labels')\n",
    "    lsds = daisy.open_ds(out_file, 'pred_lsds')\n",
    "    affs =  daisy.open_ds(out_file, 'pred_affs')\n",
    "\n",
    "    # crop a little off the edges \n",
    "    crop = gp.Coordinate((8,)*2)\n",
    "\n",
    "    roi = raw.roi.grow(-crop, -crop)\n",
    "\n",
    "    raw = raw[roi].to_ndarray()\n",
    "    labels = labels[roi].to_ndarray()\n",
    "    lsds = lsds[roi].to_ndarray()\n",
    "    affs = affs[roi].to_ndarray()\n",
    "\n",
    "    # remember to relabel gt since we cropped it\n",
    "    labels, _ = label(labels)\n",
    "    labels = labels.astype(np.uint64)\n",
    "\n",
    "    eroded_labels = erode_boundaries(labels, iterations=2)\n",
    "    \n",
    "    affs = np.stack([\n",
    "        np.zeros_like(affs[0]),\n",
    "        affs[0],\n",
    "        affs[1]])\n",
    "\n",
    "    affs = np.expand_dims(affs, axis=1)\n",
    "\n",
    "    threshold = 0.5\n",
    "\n",
    "    segmentation = get_segmentation(affs, threshold)\n",
    "    \n",
    "    segmentation, _ = label(\n",
    "        remove_small_holes(\n",
    "                segmentation.astype(bool),\n",
    "                area_threshold=256))\n",
    "\n",
    "    segmentation = segmentation.astype(np.uint64)\n",
    "    \n",
    "    ap, precision, recall, tp, fp, fn = evaluate_linear_sum_assignment(segmentation,eroded_labels)\n",
    "    \n",
    "    avg_ap += ap\n",
    "    avg_precision += precision\n",
    "    avg_recall += recall\n",
    "    avg_tp += tp\n",
    "    avg_fp += fp\n",
    "    avg_fn += fn\n",
    "    \n",
    "    print('\\n', f'metrics on {f}', '\\n')\n",
    "    \n",
    "    print(f'ap: {ap}')\n",
    "    print(f'precision: {precision}')\n",
    "    print(f'recall: {recall}')\n",
    "    print(f'tp: {tp}')\n",
    "    print(f'fp: {fp}')\n",
    "    print(f'fn: {fn}')\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        1,\n",
    "        5,\n",
    "        figsize=(15, 8),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False)\n",
    "\n",
    "    axes[0][0].imshow(raw, cmap='gray')\n",
    "    axes[0][0].set_title('raw')\n",
    "    \n",
    "    axes[0][1].imshow(np.squeeze(lsds[0]), cmap='jet')\n",
    "    axes[0][1].imshow(np.squeeze(lsds[1]), cmap='jet', alpha=0.5)\n",
    "    axes[0][1].set_title('predicted offset vectors')\n",
    "\n",
    "    axes[0][2].imshow(np.squeeze(affs[0] + affs[1]), cmap='jet')\n",
    "    axes[0][2].set_title('predicted affs')\n",
    "\n",
    "    axes[0][3].imshow(create_lut(eroded_labels))\n",
    "    axes[0][3].set_title('labels')\n",
    "\n",
    "    axes[0][4].imshow(create_lut(np.squeeze(segmentation)))\n",
    "    axes[0][4].set_title('segmentation')\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "avg_ap /= (index+1)\n",
    "avg_precision /= (index+1)\n",
    "avg_recall /= (index+1)\n",
    "avg_tp /= (index+1)\n",
    "avg_fp /= (index+1)\n",
    "avg_fn /= (index+1)\n",
    "\n",
    "print(f'Average ap: {avg_ap}')\n",
    "print(f'Average precision: {avg_precision}')\n",
    "print(f'Average recall: {avg_recall}')\n",
    "print(f'Average tp: {avg_tp}')\n",
    "print(f'Average fp: {avg_fp}')\n",
    "print(f'Average fn: {avg_fn}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
